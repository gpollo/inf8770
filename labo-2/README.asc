= Laboratoire 2

[.text-center]
Pipeline JPEG2000

[.text-center]
Gabriel-Andrew Pollo-Guilbert, _1837776_

== Question 1

Le sous-échantillonnage de RGB vers YUV 4:2:0 permet une meilleure compression
générale de l'image. En effet, ce sous-échantillonnage réduit le nombre de
pixels de 4 pour les plans U et V.

La table suivante montre les différents taux de compression causé par différent
sous-échantillonnage. Même si l'espace de couleur RGB n'est pas normalement
utilisé avec des sous-échantillonage, ils ont quand même été mis à des fins de
comparaisons. On remarque qu'un sous-échantillonnage 4:1:0 ou même 4:2:0 augmente
considérablement la compression versus aucun sous-échantillonnage, c'est-à-dire
4:4:4.

[quote]
--
include::table/stats-subsampling.asc[]
--

La table suivante montre certaines images résultantes de ces sous-échantillionnages.
On remarque premièrement que la différence entre un sous-échantillionnage YUV
4:4:4 ou 4:1:0 est pratiquement indiscernable. Pourtant, le deuxième offre
un facteur de compression de plus de 20%.

Cela dit, il est possible de voir des artéfacts de couleur si on effectue un
sous-échantillionnage similaire sur un espace de couleur RGB, même si le
facteur de compression est similaire à son égal YUV. En effet, la conversion
RGB vers YUV est utile lorsqu'on sous-échantillionne par la suite, car cela
nous permet d'enlever de l'information de couleurs auxquels nos yeux sont moins
sensible.

Bref, la sous-échantillionnage YUV permet une meilleure compression tout en
conservant une bonne qualité de couleur dans l'image. Le désavantage principale
est qu'il faut toujours reconvertir vers un espace RGB lorsque l'image doit
être affichée car la majorité des écrans ou des projecteurs fonctionnent avec
ces couleurs.

[quote]
--
.Figure 1. Comparaison des sous-échantillonnages YUV444, YUV410 et RGB410
[.text-center]
image:tests/3-decoded/yuv444.png[pdfwidth=32.88%]
image:tests/3-decoded/yuv410.png[pdfwidth=32.88%]
image:tests/3-decoded/rgb410.png[pdfwidth=32.88%]
--

== Question 2

L'avantage principal d'utiliser une transformée d'ondelettes discrètes comme
celle de Haar ou de Daubechies est de pouvoir obtenir une grande quantité
de valeurs très basses, voir nulle dans 3 des quadrants de l'image. En
augmentant le niveau de récursion de la transformée, il est possible
d'aller chercher plus valeurs zéros. La figure suivante montre les effets
de l'application d'une transformée en ondelettes de Haar de récursion 0 (image
original), 1 et 2.

[quote]
--
.Figure 2. Comparaison de différents niveaux de récusion pour les ondelettes de Haar
[.text-center]
image:tests/3-decoded/dummy0.png[pdfwidth=32.88%]
image:tests/3-decoded/dummy1.png[pdfwidth=32.88%]
image:tests/3-decoded/dummy2.png[pdfwidth=32.88%]
--

La transformée en ondelettes par elle-même ne permet pas de compresser. Elle ne
fait que déplacer l'information dans l'image. En fait, cette transformation
mathématique est même réversible dans le cas où les calculs ont été effectués
sur des nombres flottants. 

Cela dit, ce déplacement de l'information permet de concentrer les valeurs
importantes dans un coin de l'image en laissant des valeurs moins significatives
dans les autres coins. Par la suite, le quantificateur à zone morte peut
facilement éléminer les valeurs moins importantes en les arrondissant à zéro
dans le cas où elles se trouvent dans sa zone morte.

Même si à première vue, on pourrait croire qu'il suffit d'appliquer la
transformée plusieurs fois récursivement pour obtenir de plus en plus de zéro,
il faut garder à l'esprit qu'elle ne compresse pas l'information et qu'il y
aura plus de perte dans le quantificateur. Par conséquent, pour conserver une
qualité similaire tout en augmentant le nombre de récursion, il faut diminer
la taille de la zone morte dans le quantificateur.

== Question 3

En utilisant un quantificateur avec peu de perte (zone morte de largeur 1 avec
des marches de taille 1), le niveau de récusion de la transformée en ondelettes
de Haar ne devrait pas affecter significativement le taux de compression de
l'image. Cela est dû au fait que le transformée est réversible peu importe le
nombre de niveau de récusion. La table suivante montre différents niveaux de
récursions ainsi que la compression atteinte.

[quote]
--
include::table/stats-haar-recursion.asc[]
--

En effet, on peut voir que les taux de compression sont très similaire à
l'exception du niveau de récusion 0 (aucune transformée) et 1. Avec aucune
récusion et le quantificateur utilisé, le taux de compression est donc
principalement au codage LZW utilisé. Avec un niveau de récusion, il est
raisonnable d'assumer que les basses valeurs ajoutées à la fin de l'image ont
dû aider le codage LZW à trouver plus de mots identiques. En ajoutant des
niveaux de récusion, on plafonne ce que le LZW est capable de compresser.

La figure suivante montre les images résultantes d'une compression de niveau 1
et niveau 10. Il y a en effet aucune différence discernable à l'oeil nue.

[quote]
--
.Figure 3. Comparaison d'une récusion d'ondelettes de Haar de niveau 1 et 10
[.text-center]
image:tests/3-decoded/haar-1.png[pdfwidth=32.88%]
image:tests/3-decoded/haar-10.png[pdfwidth=32.88%]
--

== Question 4.1

Afin de comparer la dégradation visuel causée par la quantification, il suffit
de varier ses paramètres en conservant les paramètres constants des autres
étapes du pipeline. La figure 4 montre la dégradation visuel dû à une
augmentation de la taille de la zone morte avec un pas de 1 tandis que la
figure 5 montre la dégradation visuel dû à l'augmentation de la taille des pas
avec une zone morte de 1. Il est bon de noté que le language Go utilise des
chiffres de 16 bits pour travailler sur les pixels avant de les mettres sur
8 bits.

[quote]
--
.Figure 4. Comparaison des zones mortes de taille 1, 256 et 1024 pour la quantification à zone morte
[.text-center]
image:tests/3-decoded/deadzone-width-1.png[pdfwidth=32.88%]
image:tests/3-decoded/deadzone-width-256.png[pdfwidth=32.88%]
image:tests/3-decoded/deadzone-width-1024.png[pdfwidth=32.88%]
--

[quote]
--
.Figure 5. Comparaison des pas de taille 1, 256 et 1024 pour la quantification à zone morte
[.text-center]
image:tests/3-decoded/deadzone-delta-1.png[pdfwidth=32.88%]
image:tests/3-decoded/deadzone-delta-256.png[pdfwidth=32.88%]
image:tests/3-decoded/deadzone-delta-1024.png[pdfwidth=32.88%]
--

Dans le premier cas, on peut voir une distorsion dans les couleurs. Cela est dû
aux transformées inverses des ondelettes. Une plus grande zone morte cause une
plus grande quantité de valeur nulle dans chaque plan de couleur. Lors de la
reconstruction, une série d'addition et de soustraction des différents
quandrants propagent ces erreurs dans le reste de l'image. Certaines valeurs
de pixel se retrouvent surestimées tandis que d'autres se retrouvent
sous-estimées.

Cette hypothèse est renforcée sachant qu'une transformée en ondelette de Haar
de niveau de récursion 8 fut utilisé. En effet, on peut voir dans l'image une
série de patron carré les un emboités dans les autres. En comptant
minutieusement, on remarque que les patrons sont emboités récursivement 8 fois.

Dans le cas du changement de la taille des pas, la dégradation visuel est
différente. Au lieu de pouvoir percevoir une distorsion dans les couleurs, on
remarque plus un manque de niveau de couleurs. Cela est logique car plus la
taille du pas est élevé, plus il y aura de couleurs arrondis à une valeur de
pas spécifique. On peut aussi voir dans l'image l'effet de bloc causé par la
transformée en ondelette.

== Question 4.2

Si on calcule les taux de compression pour les deux tests ci-dessus, on obtient
de très bons résultats, comme le montre la table 3 et 4.

[quote]
--
include::table/stats-deadzone-width.asc[]
--

[quote]
--
include::table/stats-deadzone-delta.asc[]
--

Même si on obtient une compression allant jusqu'à plus de 90% dans certains
cas, il est important de comparer les images résultats précédentes. En effet,
une largeur de zone morte de 1024 ou un pas de 1024 donne de très bonnes
compressions, mais la qualité des images résultantes est inaceptable.

Avec ces données et les images précèdentes, on est en mesure de trouver des
paramètres optimales en terme de compression ainsi et de qualité. La table 5
montre 3 tests effectués et la figure suivate les images résultantes.

[quote]
--
include::table/stats-deadzone-various.asc[]
--

[quote]
--
.Figure 5. Comparaison des images résultantes de la table 5
[.text-center]
image:tests/3-decoded/deadzone-various-64-64.png[pdfwidth=32.88%]
image:tests/3-decoded/deadzone-various-128-64.png[pdfwidth=32.88%]
image:tests/3-decoded/deadzone-various-192-128.png[pdfwidth=32.88%]
--

On remarque qu'en ajustant les paramètres du quantificateur avec soins, on est
en mesure d'obtenir de très bons taux de compression (70% à 80%) tout en
conservant une bonne qualité visuel.

En utilisant les paramètres de 64/64 pour la largeur de la zone morte et la
taille des pas (bonne compression et qualité), on peut comparer différentes
ondelettes. La table 5 montre quelques tests et la figure 5 les images
résultantes. On remarque que l'ondelette de daubechies donne une meilleure
compression, mais de peu comparé à une ondelette de Haar de niveau 1. Cela dit,
l'ondelette de haar avec un plus grand niveau de récursion donne une meilleure
compression.

[quote]
--
.Figure 6. Comparaison des images résultantes de la table 6
[.text-center]
image:tests/3-decoded/mixed-haar1.png[pdfwidth=32.88%]
image:tests/3-decoded/mixed-haar4.png[pdfwidth=32.88%]
image:tests/3-decoded/mixed-daub.png[pdfwidth=32.88%]
--

[quote]
--
include::table/stats-mixed.asc[]
--

== Question 5

Afin de tester notre encodeur sur différentes images, nous utiliserons les
mêmes paramètres pour chaque encodage. Les tests suivants sont effectués avec
un sous-échantillionnage YUV 4:1:0, les ondelettes de Haar de niveau 8 et
un quantificateur à zone morte 128/64. La table 7 montre les différentes
images utilisées dans ces tests.

[quote]
--
include::table/various-images.asc[]
--

Entre l'image noir et blanc, les taux de compression sont pratiquement
identique. L'image noir contient seulement que quelques octets en moins.
Il était attendu que l'image noir soit un peu plus petite en raison de sa
grande quantité de zéro versus l'image blanche. Cela dit, les différences
ne sont pas significative et il est difficile de prédir quel étape du pipeline
a mieux performer.

En comparant l'image sombre et celle coloriée, on remarque que l'on obtient
un meilleur taux de compression pour la première. Ici, c'est dû au à la grande
quantité de valeurs basses présentent dans l'image sombre et que le
quantificateur peut arrondir dans sa zone morte. Cela dit, il aurait été
attendu d'une différence plus grande qu'environ 800 octets entre les deux
images.

Une image qui nous a surpris est celle que l'on considère normale de la voiture
de Formule Polytechnique Montréal. Celle-ci réussit à obtenir un meilleur
taux de compression que l'image sombre avec environ 800 octets en moins. Une
raison qui pourrait avoir causé cela est la conversion et le
sous-échantillionnage env YUV 4:1:0. L'image est majoritairement rouge, donc
le sous-échantillionnage a pu sauver une bonne quantité de bit dans le plan V.
Une autre possible raison serait que la majorité de rouge dans l'image a sû
aider le codage LZW, mais celle-ci est moins probable, car il y a eu plusieurs
transformations avant d'arriver à cette étape.

Les tests de gradient furent conçus pour tester si la récursion des
transformées en ondelettes favorise une direction de gradient. Selon les
résultats obtenus, les différences ne sont pas significatives.

[quote]
--
include::table/stats-various-images.asc[]
--

== Question 6

À fin de comparer le taux de compression et la qualité des images JPEG et
notre implémentation, on a compressé les images JPEG avec un paramètre de
qualité de 100%. Sachant que JPEG est un codage d'image très optimisé et très
utilisé en industrie, il est évident que ses résultats seront meilleurs que
notre pipeline. Par conséquent, on a choisie cette valeur afin de réduire le
plus possible son taux de compression pour pouvoir mieux voir la grande
différence entre les deux codages.

Pour les paramètres de notre encodeur, on choisit des paramètres que l'on croit
optimaux en terme de compression et qualité. Par conséquent, on utilise un 
sous-échantillionnage YUV 4:1:0, les ondelettes de Haar avec un niveau de
récursion de 8 et un quantificateur à zone morte 128/64. La table 9 suivante
montre les résultats.

On peut voir que notre codage JPEG2000 se compare difficilement avec le
standard JPEG. En effet, il obtient des meilleurs valeurs de PSNR et de SSIM
dans la grande majorité des images et offre des taux de compression
considérablement plus élevé que n'importe quel image résultant de notre
pipeline.

<<<
--
include::table/stat-kodak.asc[]
--
